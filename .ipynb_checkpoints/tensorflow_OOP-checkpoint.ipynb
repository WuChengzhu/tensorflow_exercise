{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目中使用tensorflow工具对MNIST数据进行分类，主要使用面向对象的方法，具体可参见这篇[博客](http://danijar.com/structuring-your-tensorflow-models/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 需要加载的工具包\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#加载数据\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义基类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "#给属性函数增加范围名称\n",
    "def doublewrap(function):\n",
    "    \"\"\"\n",
    "    A decorator decorator, allowing to use the decorator to be used without\n",
    "    parentheses if not arguments are provided. All arguments must be optional.\n",
    "    \"\"\"\n",
    "    @functools.wraps(function)\n",
    "    def decorator(*args, **kwargs):\n",
    "        if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):\n",
    "            return function(args[0])\n",
    "        else:\n",
    "            return lambda wrapee: function(wrapee, *args, **kwargs)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@doublewrap\n",
    "def define_scope(function, scope=None, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    A decorator for functions that define TensorFlow operations. The wrapped\n",
    "    function will only be executed once. Subsequent calls to it will directly\n",
    "    return the result so that operations are added to the graph only once.\n",
    "\n",
    "    The operations added by the function live within a tf.variable_scope(). If\n",
    "    this decorator is used with arguments, they will be forwarded to the\n",
    "    variable scope. The scope name defaults to the name of the wrapped\n",
    "    function.\n",
    "    \"\"\"\n",
    "    attribute = '_cache_' + function.__name__\n",
    "    name = scope or function.__name__\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            with tf.variable_scope(name, *args, **kwargs):\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "    return decorator\n",
    "\n",
    "#定义一个MNIST分类的基类\n",
    "class MnistModel:\n",
    "    def __init__(self, data_holder, target_holder, num_pixel, num_class):\n",
    "        self.data_holder = data_holder\n",
    "        self.target_holder = target_holder\n",
    "        self.num_pixel = num_pixel\n",
    "        self.num_class = num_class\n",
    "        self.prediction\n",
    "        self.optimize\n",
    "        self.accuracy\n",
    "        print('Initializing Mnist Model!') \n",
    "    \n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        return None\n",
    "    \n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        return None\n",
    "    \n",
    "    @define_scope\n",
    "    def accuracy(self):\n",
    "        return None\n",
    "    \n",
    "    #创建权重变量\n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "    #创建偏差\n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性规划"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearMnistModel(MnistModel):\n",
    "    #重构某些函数\n",
    "    \n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        #定义权重和偏置参数变量\n",
    "        W = tf.Variable(tf.zeros([self.num_pixel, self.num_class]))\n",
    "        b = tf.Variable(tf.zeros([self.num_class]))\n",
    "        logits = tf.matmul(self.data_holder, W) + b\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        cross_entropy = -tf.reduce_sum(self.target_holder*\n",
    "                                       tf.log(self.prediction))\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.01)\n",
    "        return optimizer.minimize(cross_entropy)\n",
    "\n",
    "    @define_scope\n",
    "    def accuracy(self):\n",
    "        correct_prediction = tf.equal(tf.argmax(self.target_holder,1), \n",
    "                                      tf.argmax(self.prediction,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练测试函数\n",
    "def train_test(model, num_steps, batch_size, dropout=False):\n",
    "    sess = tf.Session()\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    for step in range(num_steps):\n",
    "        batch_data, batch_labels = mnist.train.next_batch(batch_size)\n",
    "        #将数据传递给字典\n",
    "        feed_dict = {model.data_holder : batch_data, \n",
    "                     model.target_holder: batch_labels}\n",
    "        if dropout:\n",
    "            feed_dict[model.keep_prob] = 0.8\n",
    "        sess.run(model.optimize, feed_dict=feed_dict)\n",
    "        if step%100 == 0:\n",
    "            #定义模型评价指标精确度\n",
    "            feed_dict={model.data_holder: mnist.test.images, \n",
    "                       model.target_holder: mnist.test.labels}\n",
    "            if dropout:\n",
    "                feed_dict[model.keep_prob] = 1\n",
    "            accuracy = sess.run(model.accuracy, feed_dict=feed_dict)\n",
    "            print(\"测试精度：\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Mnist Model!\n",
      "测试精度： 0.3284\n",
      "测试精度： 0.8752\n",
      "测试精度： 0.9027\n",
      "测试精度： 0.9099\n",
      "测试精度： 0.9093\n",
      "测试精度： 0.9025\n",
      "测试精度： 0.9098\n",
      "测试精度： 0.9172\n",
      "测试精度： 0.9172\n",
      "测试精度： 0.9096\n",
      "测试精度： 0.098\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "batch_size = 64\n",
    "num_pixel = 784\n",
    "num_class = 10\n",
    "#定义feed数据\n",
    "#定义输入数据\n",
    "data_holder = tf.placeholder(tf.float32, [None, num_pixel])\n",
    "#输入数据对应标签\n",
    "target_holder = tf.placeholder(tf.float32, [None,num_class])\n",
    "linear_model = LinearMnistModel(data_holder, target_holder, num_pixel, num_class)\n",
    "train_test(linear_model, num_steps, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 多层神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class NeuralMnistModel(MnistModel):\n",
    "    #重构某些函数\n",
    "    def __init__(self, data_holder, target_holder, num_pixel, num_class, layers):\n",
    "        self.layers = layers\n",
    "        MnistModel.__init__(self, data_holder, target_holder, num_pixel, num_class)\n",
    "    \n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        #定义权重和偏置参数变量\n",
    "        logits = self.hiddenLayer()\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        cross_entropy = -tf.reduce_sum(self.target_holder*\n",
    "                                       tf.log(self.prediction))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "        return optimizer.minimize(cross_entropy)\n",
    "\n",
    "    @define_scope\n",
    "    def accuracy(self):\n",
    "        correct_prediction = tf.equal(tf.argmax(self.target_holder,1), \n",
    "                                      tf.argmax(self.prediction,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        return accuracy\n",
    "    \n",
    "    #@define_scope\n",
    "    def hiddenLayer(self):\n",
    "        num_layer = len(self.layers)\n",
    "        pre_units = self.num_pixel#输入节点\n",
    "        next_units = pre_units#输出节点\n",
    "        data = self.data_holder\n",
    "        #遍历每个隐层\n",
    "        for i in range(num_layer):            \n",
    "            with tf.name_scope('hidden'+str(i)):\n",
    "                #权重\n",
    "                next_units = self.layers[i]\n",
    "                weights = tf.Variable(\n",
    "                    tf.truncated_normal([pre_units, next_units],\n",
    "                                        stddev=1.0 / math.sqrt(float(pre_units))),\n",
    "                    name='weights')\n",
    "                #偏差\n",
    "                biases = tf.Variable(tf.zeros([next_units]), \n",
    "                                     name='biases')\n",
    "                hidden = tf.nn.relu(tf.matmul(data, weights) + biases)\n",
    "                data = hidden\n",
    "                pre_units = next_units\n",
    "        # Linear\n",
    "        with tf.name_scope('softmax_linear'):\n",
    "            weights = tf.Variable(\n",
    "                tf.truncated_normal([next_units, self.num_class],\n",
    "                                    stddev=1.0 / math.sqrt(float(next_units))),\n",
    "                name='weights')\n",
    "            biases = tf.Variable(tf.zeros([self.num_class]),\n",
    "                                 name='biases')\n",
    "            logits = tf.matmul(data, weights) + biases\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Mnist Model!\n",
      "测试精度： 0.2391\n",
      "测试精度： 0.8589\n",
      "测试精度： 0.9234\n",
      "测试精度： 0.9257\n",
      "测试精度： 0.9477\n",
      "测试精度： 0.9391\n",
      "测试精度： 0.9464\n",
      "测试精度： 0.9497\n",
      "测试精度： 0.948\n",
      "测试精度： 0.9585\n",
      "测试精度： 0.9475\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "batch_size = 64\n",
    "num_pixel = 784\n",
    "num_class = 10\n",
    "#定义feed数据\n",
    "#定义输入数据\n",
    "data_holder = tf.placeholder(tf.float32, [None, num_pixel])\n",
    "#输入数据对应标签\n",
    "target_holder = tf.placeholder(tf.float32, [None,num_class])\n",
    "layers = [128, 64]\n",
    "model = NeuralMnistModel(data_holder, target_holder, num_pixel, num_class, layers)\n",
    "train_test(model, num_steps, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 卷积神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CnnMnistModel(MnistModel):\n",
    "    #重构某些函数\n",
    "    def __init__(self, data_holder, target_holder, num_pixel, num_class, keep_prob):\n",
    "        self.keep_prob = keep_prob\n",
    "        MnistModel.__init__(self, data_holder, target_holder, num_pixel, num_class)\n",
    "    \n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        #定义权重和偏置参数变量\n",
    "        logits = self.cnnLayer()\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        cross_entropy = -tf.reduce_sum(self.target_holder*\n",
    "                                       tf.log(self.prediction))\n",
    "        optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "        return optimizer.minimize(cross_entropy)\n",
    "\n",
    "    @define_scope\n",
    "    def accuracy(self):\n",
    "        correct_prediction = tf.equal(tf.argmax(self.target_holder,1), \n",
    "                                      tf.argmax(self.prediction,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        return accuracy\n",
    "    \n",
    "    #@define_scope\n",
    "    def cnnLayer(self):\n",
    "        #第一层卷积\n",
    "        W_conv1 = self.weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = self.bias_variable([32])        \n",
    "        x_image = tf.reshape(self.data_holder, [-1,28,28,1])\n",
    "        #卷积后采用Relu函数激活\n",
    "        h_conv1 = tf.nn.relu(self.conv2d(x_image, W_conv1) + b_conv1)\n",
    "        #进行池化\n",
    "        h_pool1 = self.max_pool_2x2(h_conv1)\n",
    "        #第二层卷积\n",
    "        W_conv2 = self.weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = self.bias_variable([64])\n",
    "        #卷积后采用Relu函数激活\n",
    "        h_conv2 = tf.nn.relu(self.conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        #进行池化\n",
    "        h_pool2 = self.max_pool_2x2(h_conv2)\n",
    "        #全连接层\n",
    "        W_fc1 = self.weight_variable([7 * 7 * 64, 1024])\n",
    "        b_fc1 = self.bias_variable([1024])\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        #丢弃，为了增强泛化能力        \n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        #输出层，softmax\n",
    "        W_fc2 = self.weight_variable([1024, 10])\n",
    "        b_fc2 = self.bias_variable([10])\n",
    "        logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "        return logits\n",
    "    \n",
    "    #卷积函数\n",
    "    def conv2d(self, x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    #池化函数\n",
    "    def max_pool_2x2(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Mnist Model!\n",
      "测试精度： 0.085\n",
      "测试精度： 0.8633\n",
      "测试精度： 0.9172\n",
      "测试精度： 0.9332\n",
      "测试精度： 0.9444\n",
      "测试精度： 0.9555\n",
      "测试精度： 0.9578\n",
      "测试精度： 0.9634\n",
      "测试精度： 0.9624\n",
      "测试精度： 0.9688\n",
      "测试精度： 0.9709\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "batch_size = 64\n",
    "num_pixel = 784\n",
    "num_class = 10\n",
    "#定义feed数据\n",
    "#定义输入数据\n",
    "data_holder = tf.placeholder(tf.float32, [None, num_pixel])\n",
    "#输入数据对应标签\n",
    "target_holder = tf.placeholder(tf.float32, [None,num_class])\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "model = CnnMnistModel(data_holder, target_holder, num_pixel, num_class, keep_prob)\n",
    "train_test(model, num_steps, batch_size, dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
